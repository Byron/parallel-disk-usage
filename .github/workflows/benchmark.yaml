name: Benchmark

on:
  - push
  - pull_request

jobs:
  self_benchmark:
    name: Compare benchmark with itself

    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v2

      - name: Cache
        uses: actions/cache@v2.1.5
        timeout-minutes: 1
        continue-on-error: true
        if: matrix.os != 'macos-latest' # Cache causes errors on macOS
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: ${{ github.job }}-Linux-${{ hashFiles('rust-toolchain') }}-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ github.job }}-Linux-${{ hashFiles('rust-toolchain') }}-${{ hashFiles('**/Cargo.lock') }}
            ${{ github.job }}-Linux-${{ hashFiles('rust-toolchain') }}-

      - name: Build pdu
        run: |
          cargo build --release
          echo "$(pwd)/target/release" >> "$GITHUB_PATH"

      - name: Install hyperfine
        env:
          REPO: https://github.com/sharkdp/hyperfine
          VERSION: '1.11.0'
        run: |
          mkdir -p HYPERFINE.tmp
          archive_name="hyperfine-v${VERSION}-x86_64-unknown-linux-gnu"
          curl -L "${REPO}/releases/download/v${VERSION}/${archive_name}.tar.gz" > tmp.hyperfine.tar.gz
          tar xf tmp.hyperfine.tar.gz --directory=HYPERFINE.tmp
          chmod +x "HYPERFINE.tmp/${archive_name}/hyperfine"
          echo "$(pwd)/HYPERFINE.tmp/${archive_name}" >> "$GITHUB_PATH"

      - name: Inspect commands
        run: |
          which pdu
          which hyperfine
          hyperfine --version

      - name: Prepare directory to be measured
        run: |
          mkdir -p tmp.sample
          curl -L https://github.com/torvalds/linux/archive/refs/tags/v5.12.zip > tmp.sample.zip
          unzip tmp.sample.zip -d tmp.sample

      - name: Generate benchmark reports
        run: |
          reports=(
            --export-asciidoc tmp.hyperfine-report.adoc
            --export-csv      tmp.hyperfine-report.csv
            --export-json     tmp.hyperfine-report.json
            --export-markdown tmp.hyperfine-report.md
          )
          parameters=(
            -L pdu           'pdu'
            -L quantity      'len,blksize,blocks'
            -L minimal-ratio '0.1,0.05,0.0.1,0'
            -L max-depth     '1,3,5,10'
          )
          commands=(
            '{pdu} --quantity={quantity} --max-depth={max-depth} tmp.sample'
            '{pdu} --quantity={quantity} --max-depth={max-depth} --no-sort tmp.sample'
          )
          arguments=(
            --warmup=3
            "${reports[@]}"
            "${parameters[@]}"
            "${commands[@]}"
          )
          hyperfine "${arguments[@]}" 2>&1 | tee tmp.hyperfine.log

      - name: Post generated benchmark reports to pull request as a comment
        uses: actions/github-script@v4.0.2
        if: github.event_name == 'pull_request'
        continue-on-error: false # TODO: set this to false
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const path = require('path')
            const { readFileSync } = require('fs')
            const process = require('process')
            const cwd = process.cwd()

            function loadReport(ext) {
              const filePath = path.join(cwd, `tmp.hyperfine-report.${ext}`)
              console.debug(`read ${filePath}...`)
              return readFileSync(filePath, 'utf-8')
            }

            function codeBlock(detailsSummary, reportLang, reportExt) {
              return [
                '<details><summary>',
                detailsSummary,
                '</summary>',
                '',
                '```' + reportLang,
                loadReport(reportExt),
                '```',
                '',
                '</details>',
              ].join('\n')
            }

            const body = [
              '## Benchmark Results',
              '',
              loadReport('md'),
              '',
              codeBlock('hyperfine logs', 'log', 'log'),
              '',
              codeBlock('report AsciiDoc', 'asciidoc', 'adoc'),
              '',
              codeBlock('report CSV', 'csv', 'csv'),
              '',
              codeBlock('report JSON', 'json', 'json'),
              '',
            ].join('\n')

            await github.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body,
            })

      - name: Upload benchmark reports
        uses: actions/upload-artifact@v2.2.3
        with:
          name: benchmark-reports
          path: tmp.hyperfine-report.*

      - name: 'Benchmark: --quantity'
        run: |
          commands=(
            'pdu --quantity=len tmp.sample'
            'pdu --quantity=blksize tmp.sample'
            'pdu --quantity=blocks tmp.sample'
          )
          hyperfine --warmup=3 "${commands[@]}"

      - name: 'Benchmark: [--no-sort]'
        run: |
          commands=(
            'pdu tmp.sample'
            'pdu --no-sort tmp.sample'
          )
          hyperfine --warmup=3 "${commands[@]}"

      - name: 'Benchmark: --minimal-ratio'
        run: |
          commands=(
            'pdu --minimal-ratio=0.1 tmp.sample'
            'pdu --minimal-ratio=0.01 tmp.sample'
            'pdu --minimal-ratio=0 tmp.sample'
          )
          hyperfine --warmup=3 "${commands[@]}"

      - name: 'Benchmark: [--max-depth]'
        run: |
          commands=(
            'pdu tmp.sample'
            'pdu --max-depth=5 tmp.sample'
            'pdu --max-depth=3 tmp.sample'
            'pdu --max-depth=1 tmp.sample'
          )
          hyperfine --warmup=3 "${commands[@]}"

      - name: 'Benchmark: [--max-depth=1] [--no-sort]'
        run: |
          commands=(
            'pdu tmp.sample'
            'pdu --max-depth=1 tmp.sample'
            'pdu --no-sort tmp.sample'
            'pdu --max-depth=1 --no-sort tmp.sample'
          )
          hyperfine --warmup=3 "${commands[@]}"

  competing_benchmark:
    name: Compare benchmark with similar tools

    runs-on: ubuntu-latest

    # run benchmark sequentially to reduce noises
    needs:
      - self_benchmark

    steps:
      - uses: actions/checkout@v2

      - name: Cache
        uses: actions/cache@v2.1.5
        timeout-minutes: 1
        continue-on-error: true
        if: matrix.os != 'macos-latest' # Cache causes errors on macOS
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: ${{ github.job }}-Linux-${{ hashFiles('rust-toolchain') }}-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ github.job }}-Linux-${{ hashFiles('rust-toolchain') }}-${{ hashFiles('**/Cargo.lock') }}
            ${{ github.job }}-Linux-${{ hashFiles('rust-toolchain') }}-

      - name: Build pdu
        run: |
          cargo build --release
          echo "$(pwd)/target/release" >> "$GITHUB_PATH"

      - name: Install dust
        env:
          REPO: https://github.com/bootandy/dust
          VERSION: '0.5.4'
        run: |
          mkdir -p DUST.tmp
          archive_name="dust-v${VERSION}-x86_64-unknown-linux-gnu"
          curl -L "${REPO}/releases/download/v${VERSION}/${archive_name}.tar.gz" > tmp.dust.tar.gz
          tar xf tmp.dust.tar.gz --directory=DUST.tmp
          chmod +x "DUST.tmp/${archive_name}/dust"
          echo "$(pwd)/DUST.tmp/${archive_name}" >> "$GITHUB_PATH"

      - name: Install dutree
        env:
          REPO: https://github.com/nachoparker/dutree
          VERSION: '0.2.15'
        run: |
          mkdir -p DUTREE.tmp
          curl -L "${REPO}/releases/download/v${VERSION}/dutree" > DUTREE.tmp/dutree
          chmod +x DUTREE.tmp/dutree
          echo "$(pwd)/DUTREE.tmp" >> "$GITHUB_PATH"

      - name: Install hyperfine
        env:
          REPO: https://github.com/sharkdp/hyperfine
          VERSION: '1.11.0'
        run: |
          mkdir -p HYPERFINE.tmp
          archive_name="hyperfine-v${VERSION}-x86_64-unknown-linux-gnu"
          curl -L "${REPO}/releases/download/v${VERSION}/${archive_name}.tar.gz" > tmp.hyperfine.tar.gz
          tar xf tmp.hyperfine.tar.gz --directory=HYPERFINE.tmp
          chmod +x "HYPERFINE.tmp/${archive_name}/hyperfine"
          echo "$(pwd)/HYPERFINE.tmp/${archive_name}" >> "$GITHUB_PATH"

      - name: Inspect command locations
        run: |
          which pdu
          which dust
          which dutree
          which du
          which hyperfine

      - name: Inspect versions of the other tools
        run: |
          dust --version
          dutree --version
          du --version
          hyperfine --version

      - name: Prepare directory to be measured
        run: |
          mkdir -p tmp.sample
          curl -L https://github.com/torvalds/linux/archive/refs/tags/v5.12.zip > tmp.sample.zip
          unzip tmp.sample.zip -d tmp.sample

      - name: 'Benchmark: len'
        run: |
          commands=(
            'pdu --quantity=len tmp.sample'
            'dust --apparent-size tmp.sample'
            'dutree tmp.sample'
            'du --apparent-size tmp.sample'
          )
          hyperfine --warmup=3 "${commands[@]}"

      - name: 'Benchmark: blksize'
        run: |
          commands=(
            'pdu --quantity=blksize tmp.sample'
            'dust tmp.sample'
            'dutree --usage tmp.sample'
            'du tmp.sample'
          )
          hyperfine --warmup=3 "${commands[@]}"

      - name: 'Benchmark: top-down'
        run: |
          commands=(
            'pdu --top-down tmp.sample'
            'dust --apparent-size --reverse tmp.sample'
            'dutree tmp.sample'
          )
          hyperfine --warmup=3 "${commands[@]}"

      - name: 'Benchmark: summary'
        run: |
          commands=(
            'pdu --max-depth=1 tmp.sample'
            'dutree --summary tmp.sample'
            'du --apparent-size --total tmp.sample'
          )
          hyperfine --warmup=3 "${commands[@]}"

      - name: 'Benchmark: extreme details'
        run: |
          commands=(
            'pdu --minimal-ratio=0 tmp.sample'
            'dutree tmp.sample'
            'du --apparent-size tmp.sample'
          )
          hyperfine --warmup=3 "${commands[@]}"

      - name: 'Benchmark: no sort'
        run: |
          commands=(
            'pdu --no-sort tmp.sample'
            'du --apparent-size tmp.sample'
          )
          hyperfine --warmup=3 "${commands[@]}"

      - name: 'Benchmark: no sort, summary'
        run: |
          commands=(
            'pdu --no-sort --max-depth=1 tmp.sample'
            'du --apparent-size --total tmp.sample'
          )
          hyperfine --warmup=3 "${commands[@]}"
